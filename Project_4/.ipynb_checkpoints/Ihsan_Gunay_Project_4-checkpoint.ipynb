{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest, SelectFwe, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def produce_modifications(X_train, y_train, train_indices, target_indices, X_val, y_val_na):\n",
    "    for i in target_indices:\n",
    "\n",
    "        if i in train_indices:\n",
    "            mod0 = np.copy(y_train)\n",
    "            mod0[i] = 1 - mod0[i]\n",
    "            yield X_train, mod0, train_indices, X_val, y_val_na\n",
    "\n",
    "            mod1 = list(train_indices)\n",
    "            mod1.remove(i)\n",
    "            yield X_train, y_train, mod1, X_val, y_val_na\n",
    "\n",
    "        else:\n",
    "            mod0 = list(train_indices)\n",
    "            mod0.append(i)\n",
    "            yield X_train, y_train, mod0, X_val, y_val_na\n",
    "\n",
    "            mod1 = np.copy(y_train)\n",
    "            mod1[i] = 1 - mod1[i]\n",
    "            yield X_train, mod1, mod0, X_val, y_val_na\n",
    "\n",
    "def test_modification(test):\n",
    "    X_train, y_train, train_indices, X_val, y_val_na = test\n",
    "    \n",
    "    clf = LinearRegression(copy_X=True)\n",
    "    clf.fit(X_train[train_indices],y_train[train_indices])\n",
    "    new_error = clf.residues_\n",
    "    \n",
    "    return new_error, y_train, train_indices\n",
    "\n",
    "def ce_squared(T, probs):\n",
    "    return ((T*probs)**2).sum()/len(probs)\n",
    "\n",
    "def process_dataset(X_train, y_train, X_test):\n",
    "    # Select top 50 features for mutual info with y\n",
    "    minfos = mutual_info_classif(X_train, y_train) \n",
    "    minds = minfos.argsort()[-50:]\n",
    "    X_train = X_train[:, minds]\n",
    "    \n",
    "    # Map it down to 30 dims while preserving ~99% of variance\n",
    "    pca = PCA(n_components=30) \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    \n",
    "    # Transform X_test\n",
    "    X_test = pca.transform(X_test[:,minds])\n",
    "    np.random.shuffle(X_test)\n",
    "    \n",
    "    # Undersample & seperate a validation set\n",
    "    pinds = np.where(y_train == 1)[0] \n",
    "    ninds = np.where(y_train == 0)[0]\n",
    "    \n",
    "    np.random.shuffle(ninds)\n",
    "    \n",
    "    train_ninds = ninds[:500]\n",
    "    val_ninds = ninds[-300:]\n",
    "    \n",
    "    train_pinds = pinds[:300]\n",
    "    val_pinds = pinds[-100:]\n",
    "    \n",
    "    X_tr = np.vstack((X_train[train_pinds], X_train[train_ninds]))\n",
    "    y_tr = np.append(y_train[train_pinds], y_train[train_ninds])\n",
    "    \n",
    "    X_va = np.vstack((X_train[val_pinds], X_train[val_ninds]))\n",
    "    y_va = np.append(y_train[val_pinds], y_train[val_ninds])\n",
    "    \n",
    "    tr_inds = list(range(X_tr.shape[0]))\n",
    "    np.random.shuffle(tr_inds)\n",
    "    \n",
    "    X_train = X_tr[tr_inds]\n",
    "    y_train = y_tr[tr_inds]\n",
    "    \n",
    "    va_inds = list(range(X_va.shape[0]))\n",
    "    np.random.shuffle(va_inds)\n",
    "    \n",
    "    X_val = X_va[va_inds]\n",
    "    y_val = y_va[va_inds]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test    \n",
    "\n",
    "def modify_dataset(X_train, y_train, X_val, y_val):\n",
    "    start_ind = 0\n",
    "    batch_size = 100\n",
    "    end_ind = start_ind + batch_size\n",
    "\n",
    "    y_val_na = y_val[:, np.newaxis]\n",
    "    y_val_na = np.append(y_val_na, 1-y_val_na, axis=1)\n",
    "    \n",
    "    clf = LinearRegression(copy_X=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    best_error = clf.residues_\n",
    "    best_y_train = y_train\n",
    "    best_train_indices = list(range(X_train.shape[0]))\n",
    "\n",
    "    while end_ind <= X_train.shape[0]:\n",
    "        target_indices = range(start_ind, end_ind)\n",
    "        mods = produce_modifications(X_train, best_y_train, best_train_indices, target_indices, X_val, y_val_na)\n",
    "\n",
    "        test_results = list(map(test_modification, mods))\n",
    "        test_results.append((best_error, best_y_train, best_train_indices))\n",
    "        best_error, best_y_train, best_train_indices = min(test_results, key=lambda x: x[0])\n",
    "\n",
    "        print('Processed: {:5d} samples,\\tcurrent error is {:0.4f}'.format(end_ind, best_error))\n",
    "        start_ind += batch_size\n",
    "        end_ind += batch_size\n",
    "        \n",
    "    return X_train[best_train_indices], best_y_train[best_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array(pd.read_csv('train.csv', header=None))\n",
    "y_train = np.array(pd.read_csv('trainlabels.csv', header=None)).ravel()\n",
    "X_test = np.array(pd.read_csv('test.csv', header=None))\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test = process_dataset(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed:   100 samples,\tcurrent error is 74.8882\n",
      "Processed:   200 samples,\tcurrent error is 74.2771\n",
      "Processed:   300 samples,\tcurrent error is 73.7341\n",
      "Processed:   400 samples,\tcurrent error is 70.0449\n",
      "Processed:   500 samples,\tcurrent error is 69.4833\n",
      "Processed:   600 samples,\tcurrent error is 68.9168\n",
      "Processed:   700 samples,\tcurrent error is 68.1518\n",
      "Processed:   800 samples,\tcurrent error is 67.4755\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "    X, y = modify_dataset(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X: uncorrelated X_train: 0.74\n",
    "\n",
    "X2: top 50 mi values of X: 0.81\n",
    "\n",
    "X3: top 30 mi values of X: 0.87\n",
    "\n",
    "X4: top 20 mi values of X: 0.80\n",
    "\n",
    "X5: 20 pca on x4: 0.90, 0.74\n",
    "\n",
    "X6: 30 pca on top 50 mi of reduced x: 0.88 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=1000, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.vstack((X, X_val))\n",
    "y = np.append(y, y_val)\n",
    "\n",
    "svm = SVC(class_weight='balanced', cache_size=1000)\n",
    "auc = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'gamma': 0.10000000000000001}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 10 ** np.arange(-3, 3).astype('float')\n",
    "g = 10 ** np.arange(-3, 3).astype('float')\n",
    "params = {'C':c, 'gamma':g}\n",
    "\n",
    "clf = GridSearchCV(svm, params, scoring=auc)\n",
    "clf.fit(X, y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5.0, 'gamma': 0.1388888888888889}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c =  np.linspace(5, 15, 10).astype('float')\n",
    "g = np.linspace(0.05, 0.15, 10).astype('float')\n",
    "params = {'C':c, 'gamma':g}\n",
    "\n",
    "clf = GridSearchCV(svm, params, scoring=auc)\n",
    "clf.fit(X, y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = clf.decision_function(X_test)\n",
    "preds = pd.DataFrame(preds)\n",
    "preds.index += 1\n",
    "preds.to_csv('out.csv', index_label='Id', header=['Prediction'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
